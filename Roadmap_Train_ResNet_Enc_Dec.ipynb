{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"colab":{"name":"Roadmap_Train_ResNet_Enc_Dec.ipynb","provenance":[{"file_id":"1pMgI7eLcu5rKpHiOxQZfr9gq5pyh3wxq","timestamp":1589290140508}],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"NkXdXWk6gbvp","colab_type":"code","outputId":"174531e2-b480-48c1-d3da-e7000918a669","executionInfo":{"status":"ok","timestamp":1589343517731,"user_tz":240,"elapsed":1176,"user":{"displayName":"Ningyuan Huang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjadRAYd-E5oP939_K-8dA89bUsBifSpJlzqm0e=s64","userId":"08489882707199332059"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"h0JhCXGzgk5D","colab_type":"code","outputId":"89a4208f-2490-4840-ca7e-3d03c7e295de","executionInfo":{"status":"ok","timestamp":1589343517734,"user_tz":240,"elapsed":1167,"user":{"displayName":"Ningyuan Huang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjadRAYd-E5oP939_K-8dA89bUsBifSpJlzqm0e=s64","userId":"08489882707199332059"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%cd /content/drive/My\\ Drive/DL\\ Project/Submission"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/DL Project/Submission\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cVaneRAWgVxl","colab_type":"code","colab":{}},"source":["## import libraries\n","import numpy as np\n","import torch\n","from torch.autograd import Variable\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm_notebook\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from models import resnet18_encoderdecoder, resnet18_encoderdecoder_wbottleneck, resnet50_encoderdecoder\n","from models import resnet18_coach_vae\n","import torchvision\n","import torch.optim as optim\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","## fix seeds\n","torch.cuda.manual_seed(7)\n","torch.manual_seed(7)\n","np.random.seed(7)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nWHjXnALmUdT","colab_type":"code","outputId":"491ba7dc-39f4-44dc-fc6b-2942d4d2ac18","executionInfo":{"status":"ok","timestamp":1589343536332,"user_tz":240,"elapsed":4565,"user":{"displayName":"Ningyuan Huang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjadRAYd-E5oP939_K-8dA89bUsBifSpJlzqm0e=s64","userId":"08489882707199332059"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["!pip install kornia\n","import kornia"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: kornia in /usr/local/lib/python3.6/dist-packages (0.3.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from kornia) (1.18.4)\n","Requirement already satisfied: torch==1.5.0 in /usr/local/lib/python3.6/dist-packages (from kornia) (1.5.0+cu101)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5.0->kornia) (0.16.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oWCmmQkkrPyV","colab_type":"code","colab":{}},"source":["### Homography transform matrices\n","# 6 x 3 x 3: order same as camera CAM_FRONT_LEFT, CAM_FRONT, CAM_FRONT_RIGHT, CAM_BACK_LEFT, CAM_BACK, Ùè∞ÄCAM_BACK_RIGHT\n","M_matrices = torch.tensor([\n","    # CAM_FRONT_LEFT\n","    [[-6.92946073e-02, -1.17143003e+00,  1.64122408e+02],\n","        [-1.33781874e-14, -1.67019853e+00,  2.34084846e+02],\n","        [-7.00394603e-17, -7.63146706e-03,  1.00000000e+00]], \n","    # CAM_FRONT\n","    [[-6.92636526e-02, -1.17089785e+00,  1.64264194e+02],\n","        [-1.12965193e-14, -1.66944201e+00,  2.34140507e+02],\n","        [-5.76795556e-17, -7.62799727e-03,  1.00000000e+00]],\n","    # CAM_FRONT_RIGHT\n","    [[-7.02452787e-02, -1.17762492e+00,  1.64369634e+02],\n","        [-2.27595720e-14, -1.67903365e+00,  2.34318471e+02],\n","        [-1.16009632e-16, -7.67182090e-03,  1.00000000e+00]],\n","    # CAM_BACK_LEFT\n","    [[-6.94775392e-02, -1.17675499e+00,  1.64135286e+02],\n","        [-1.19904087e-14, -1.67779415e+00,  2.34164782e+02],\n","        [-5.78963960e-17, -7.66615368e-03,  1.00000000e+00]],\n","    # CAM_BACK\n","    [[-6.82085369e-02, -1.16228084e+00,  1.64011808e+02],\n","        [-1.23234756e-14, -1.65715610e+00,  2.33912863e+02],\n","        [-6.39679282e-17, -7.57186452e-03,  1.00000000e+00]],\n","    # CAM_BACK_RIGHT\n","    [[-6.91003275e-02, -1.16814423e+00,  1.63997347e+02],\n","        [-1.59872116e-14, -1.66551463e+00,  2.34087152e+02],\n","        [-8.30498864e-17, -7.61006318e-03,  1.00000000e+00]]\n","        ])\n","# rotation matrices\n","M_rotations = torch.tensor([[[ 5.0000e-01,  8.6603e-01, -1.8330e+01],\n","      [-8.6603e-01,  5.0000e-01,  1.8725e+02]],\n","\n","    [[ 1.0000e+00,  0.0000e+00,  0.0000e+00],\n","      [-0.0000e+00,  1.0000e+00,  0.0000e+00]],\n","\n","    [[ 5.0000e-01, -8.6603e-01,  1.7133e+02],\n","      [ 8.6603e-01,  5.0000e-01, -7.7752e+01]],\n","\n","    [[-5.0000e-01,  8.6603e-01,  1.3467e+02],\n","      [-8.6603e-01, -5.0000e-01,  2.9675e+02]],\n","\n","    [[-1.0000e+00,  8.7423e-08,  3.0600e+02],\n","      [-8.7423e-08, -1.0000e+00,  2.1900e+02]],\n","\n","    [[-5.0000e-01, -8.6603e-01,  3.2433e+02],\n","      [ 8.6603e-01, -5.0000e-01,  3.1748e+01]]])\n","\n","#flip 90 degree to align car facing right\n","M_flip = torch.tensor([[[-4.3711e-08, -1.0000e+00,  4.3800e+02],\n","      [ 1.0000e+00, -4.3711e-08,  0.0000e+00]]])\n","\n","M_matrices = M_matrices.cuda()\n","M_rotations = M_rotations.cuda()\n","M_flip = M_flip.cuda()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"82Pi5oMiGOfA","colab_type":"code","colab":{}},"source":["import kornia.augmentation as K\n","#helper function to stitch 6 BEV views\n","def stitch(x, M_matrices,M_rotations, M_flip, label=True):\n","    #Preprocessing: image stitch\n","    data = [] #list to store all the features maps from multi-views\n","    for i in range(6):\n","        #get a batch of *same* view images\n","        img_batch = x[:,i,:,:,:] # torch.stack(x)[:,i,:,:,:] #\n","        img_warp = kornia.warp_perspective(img_batch, M_matrices[i].unsqueeze(0).repeat(len(x), 1,1), dsize=(219, 306))\n","        img_rotated = kornia.warp_affine(img_warp, M_rotations[i].unsqueeze(0).repeat(len(x), 1,1), dsize=(219, 306))\n","        data.append(img_rotated)\n","\n","    data = torch.cat(data, dim=0).view(6,len(x),3,219,306)\n","    #max pool feature maps from multi-view:black canvas and ensemble\n","    h, w = 219, 306\n","    #print(h,w)\n","    agg = torch.zeros((x.shape[0],3,2*h,2*w)) #[batch_size, 3 ,h, w], twice width/height\n","    if torch.cuda.is_available():\n","        agg = agg.cuda()\n","    #two bases: front and back view\n","    agg[:,:, 0:h, (w-w//2):(w+w//2)] = data[1]\n","    agg[:,:, h:, (w-w//2):(w+w//2)] = data[4]\n","    #top left\n","    agg[:,:, (0+55):(h+55), (0+55):(w+55)] = torch.max(data[0], agg[:,:, (0+55):(h+55), (0+55):(w+55)])\n","    #top right\n","    agg[:,:,(0+55):(h+55), (w-55):(-55)] = torch.max(data[2], agg[:,:,(0+55):(h+55), (w-55):(-55)])\n","    #bottom left\n","    agg[:,:,(h-55):(-55), (0+55):(w+55)] = torch.max(data[3],agg[:,:,(h-55):(-55), (0+55):(w+55)])\n","    #bottom right\n","    agg[:,:,(h-55):(-55), (w-55):(-55)] = torch.max(data[5],agg[:,:,(h-55):(-55),(w-55):(-55)])\n","\n","    #center-crop\n","    crop_fn = kornia.augmentation.CenterCrop(size=438)\n","    agg = crop_fn(agg)\n","\n","    #flip 90 degree\n","    agg = kornia.warp_affine(agg, M_flip.repeat(len(x), 1,1), dsize=(438,438))\n","    #Normalize color\n","    if label:\n","      normalize = K.Normalize(torch.tensor([0.698, 0.718, 0.730]),\n","                              torch.tensor([0.322, 0.313, 0.308]))\n","    else:\n","      normalize = K.Normalize(torch.tensor([0.548, 0.597, 0.630]),\n","                         torch.tensor([0.339, 0.340, 0.342]))\n","\n","    return normalize(agg)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LM3OtxrlHEVG","colab_type":"code","colab":{}},"source":["#inverse back for visualization\n","from torchvision import transforms\n","def inv_transform(x, label=True):\n","  if label:\n","    inv_transform = transforms.Compose([transforms.Normalize(mean = [ 0., 0., 0. ],\n","                                                            std = [1/0.322, 1/0.313, 1/0.308]),\n","                                        transforms.Normalize(mean = [-0.698, -0.718, -0.730],\n","                                                             std = [1., 1., 1.])])\n","  else:\n","    inv_transform = transforms.Compose([transforms.Normalize(mean = [ 0., 0., 0. ],\n","                                                            std = [1/0.339, 1/0.340, 1/0.342]), \n","                                        transforms.Normalize(mean = [-0.548, -0.597, -0.630],\n","                                                             std = [1., 1., 1.])])\n","  return inv_transform(x)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FsEqDr2vgVya","colab_type":"text"},"source":["___"]},{"cell_type":"markdown","metadata":{"id":"1cMUeyOHgVyb","colab_type":"text"},"source":["## Train Final Stitched Model"]},{"cell_type":"code","metadata":{"id":"0Ld53u6OYDn7","colab_type":"code","colab":{}},"source":["from model_lane_res_stitch import Stitch_Classfier, resnet18_encoderdecoder\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","net = resnet18_encoderdecoder().cuda() \n","net_segmentation = Stitch_Classfier(net, n_class=2).cuda()\n","del(net)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SQv4MLTggVyd","colab_type":"code","colab":{}},"source":["from helper import collate_fn, compute_ts_road_map\n","from data_loading import get_loaders"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"p2bgmUxrgVyf","colab_type":"code","colab":{}},"source":["train_seg_loss = []\n","val_seg_loss = []"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ig9_5tfiXaW3","colab_type":"code","colab":{}},"source":["train_seg_loader, val_seg_loader = get_loaders('labeled', batch_size = 16,visual=True)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-KaFidYWgVyk","colab_type":"code","colab":{}},"source":["def train_segmentation(epoch, net_segmentation, seg_optimizer):\n","    progbar = tqdm_notebook(total=len(train_seg_loader), desc='Train')\n","    loss = kornia.losses.DiceLoss()\n","    net_segmentation.train()\n","        \n","    train_seg_loss.append(0)\n","    seg_optimizer.zero_grad()\n","    hist = np.zeros((nClasses, nClasses))\n","    for batch_idx, data in enumerate(train_seg_loader):\n","      sample, target, road_image = data\n","      BEV_inputs = stitch(torch.stack(sample).cuda(),M_matrices, M_rotations, M_flip, label=True)\n","      road_image = torch.stack(road_image).long().cuda()\n","      outputs = net_segmentation(BEV_inputs)\n","      total_loss = loss(outputs, road_image)   \n","      total_loss.backward()\n","        \n","      seg_optimizer.step()\n","      seg_optimizer.zero_grad()\n","        \n","      train_seg_loss[-1] += total_loss.data\n","        \n","      _, predicted = torch.max(outputs.data, 1)\n","\n","      progbar.set_description('Train (loss=%.4f)' % (train_seg_loss[-1]/(batch_idx+1)))\n","      progbar.update(1)\n","\n","    train_seg_loss[-1] = train_seg_loss[-1]/len(train_seg_loader)\n","    \n","    \n","def val_segmentation(epoch, net_segmentation):\n","    global best_score\n","    global val_score\n","\n","    loss = kornia.losses.DiceLoss()\n","    progbar = tqdm_notebook(total=len(val_seg_loader), desc='Val')\n","    net_segmentation.eval()\n","        \n","    val_seg_loss.append(0)\n","    total = 0\n","    total_ts_road_map = 0\n","    with torch.no_grad():\n","      for batch_idx, data in enumerate(val_seg_loader):\n","        sample, target, road_image = data\n","        total += 1\n","        BEV_inputs = stitch(torch.stack(sample).cuda(),M_matrices, M_rotations, M_flip,label=True)\n","        road_image = torch.stack(road_image).long().cuda()\n","        outputs = net_segmentation(BEV_inputs)\n","        total_loss = loss(outputs, road_image) \n","        val_seg_loss[-1] += total_loss.data\n","        predicted_road_map = outputs.data.max(1)[1] # get the index of the max (no need to normalize)     \n","        ts_road_map = compute_ts_road_map(predicted_road_map, road_image)  \n","        total_ts_road_map += ts_road_map\n","        progbar.set_description('Val (loss=%.4f, Score=%.4f)' % (val_seg_loss[-1]/(batch_idx+1), ts_road_map))\n","        progbar.update(1)\n","      val_seg_loss[-1] = val_seg_loss[-1]/len(val_seg_loader)\n","      val_score = total_ts_road_map / total\n","      print(f'Road Map Score: {total_ts_road_map / total:.4}')\n","\n","      if best_score < val_score:\n","          best_score = val_score\n","          print('Saving..')\n","          torch.save(net_segmentation.state_dict(), 'resnet18_stitch')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sOZHN8gQOnY-","colab_type":"code","colab":{}},"source":["best_score = 0.63"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qw3DH1-RiOQ3","colab_type":"code","colab":{}},"source":["###train from sratch\n","best_score = 0.63 #previous benchmark\n","learning_rate = 1e-3\n","seg_optimizer = optim.SGD(net_segmentation.parameters(), lr=learning_rate, momentum=0.9, weight_decay=1e-3)\n","progbar = tqdm_notebook(total=30, desc='Epochs')\n","for epoch in range(0, 30):\n","  if epoch+1 % 10 == 0:\n","    learning_rate /= 10 #lr decay\n","    print('lr decay...')\n","    for param_group in seg_optimizer.param_groups: \n","      param_group['lr'] = learning_rate\n","  print('starting epoch', epoch)\n","  train_segmentation(epoch, net_segmentation=net_segmentation, seg_optimizer=seg_optimizer)\n","  val_segmentation(epoch, net_segmentation=net_segmentation)\n","  progbar.update(1)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OiscDfoXKwW_","colab_type":"text"},"source":["## Train ResNet50 with pretrained weights"]},{"cell_type":"code","metadata":{"id":"UWgrdQHgLhMg","colab_type":"code","colab":{}},"source":["from model_lane import Multi_Classfier, resnet50_encoderdecoder, warp_transform\n","net = resnet50_encoderdecoder().cuda() \n","net.load_state_dict(torch.load('./47-DreamTeam-Round3/resnet50_bs16')) #pretrained weights\n","net_segmentation = Multi_Classfier(net, n_class = 2).cuda()\n","del(net)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MjZmPGDTz-nx","colab_type":"code","colab":{}},"source":["#Pretrain: freeze layers - first 8 layers before decoder; train for 10 epochs\n","for i, child in enumerate(net_segmentation.features.children()): \n","  for param in child.parameters():\n","    param.requires_grad = False #freeze weight\n","  if i == 7:\n","    break\n","seg_optimizer = optim.Adam(filter(lambda p: p.requires_grad, net_segmentation.parameters()), lr=1e-3, weight_decay=1e-4, betas=(0.9, 0.999)) \n","print('num of trainable params:', sum(p.numel() for p in net_segmentation.parameters() if p.requires_grad))\n","print('num of total params:', sum(p.numel() for p in net_segmentation.parameters()))\n","progbar = tqdm_notebook(total=10, desc='Epochs')\n","for epoch in range(0, 10):\n","  print('starting epoch', epoch)\n","  train_segmentation(epoch, net_segmentation=net_segmentation, seg_optimizer=seg_optimizer)\n","  val_segmentation(epoch, net_segmentation=net_segmentation)\n","  progbar.update(1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4h7YjlmADFUI","colab_type":"code","colab":{}},"source":["#Unfreeze encoder layers for end-to-end training\n","for i, child in enumerate(net_segmentation.features.children()): \n","  for param in child.parameters():\n","    param.requires_grad = True\n","  if i == 7:\n","    break\n","print('num of trainable params:', sum(p.numel() for p in net_segmentation.parameters() if p.requires_grad))\n","print('num of total params:', sum(p.numel() for p in net_segmentation.parameters()))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"-r6ip1-rgVym","colab_type":"code","colab":{}},"source":["###End-to-end training\n","\n","seg_optimizer = optim.Adam(net_segmentation.parameters(), lr=1e-3, weight_decay=1e-4, betas=(0.9, 0.999)) \n","best_score = 0.63\n","learning_rate = 1e-3\n","progbar = tqdm_notebook(total=30, desc='Epochs')\n","for epoch in range(0, 30):\n","  if epoch+1 % 10 == 0:\n","    learning_rate /= 10 #lr decay\n","    print('lr decay...')\n","    for param_group in seg_optimizer.param_groups: \n","      param_group['lr'] = learning_rate\n","  print('starting epoch', epoch)\n","  train_segmentation(epoch, net_segmentation=net_segmentation, seg_optimizer=seg_optimizer)\n","  val_segmentation(epoch, net_segmentation=net_segmentation)\n","  progbar.update(1)"],"execution_count":0,"outputs":[]}]}